{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://musicinformationretrieval.com/stft.html\n",
    "https://music.stackexchange.com/questions/34402/understanding-midi-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import IPython.display as ipd\n",
    "MIDInotes=[21,108]\n",
    "sr=44100\n",
    "bins_per_octave=36\n",
    "n_octave=7\n",
    "n_bins=n_octave*bins_per_octave\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import os,glob\n",
    "import os.path as osp\n",
    "from torch import nn\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from importlib import import_module\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "print(sr)\n",
    "\n",
    "#import midi_to_mat as mm\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file='C:\\\\Users\\\\Li_Sh\\\\18797proj\\\\piano-midi\\\\test\\\\alb_se5.wav'\n",
    "midi_file='C:\\\\Users\\\\Li_Sh\\\\18797proj\\\\piano-midi\\\\test\\\\alb_se5.mid'\n",
    "x, _ = librosa.load(audio_file, sr=sr)\n",
    "kernel_size=7\n",
    "win_width=16\n",
    "print(sr)\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples = 434304, sr = 44100. Total duration = samples/sr\n",
    "Window size for CQT = #samples/CQT.shape[0] = ~512 (or each frame is of 512 samples, or the window size)\n",
    "That's why we have 849 data points in the CQT.\n",
    "Also second duration of each frame is 512/44100 = ~ 0.0116 second or close to 12 millisecond is the granularity at which each frame is transformed to a CQT spectrum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
    "    # Use librosa's specshow function for displaying the piano roll\n",
    "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
    "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
    "                             fmin=pretty_midi.note_number_to_hz(start_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_audio(audio_file, midi_file):\n",
    "    x, _ = librosa.load(audio_file, sr=sr)\n",
    "    print(\"Music file length=%s, sampling_rate=%s\" % (x.shape[0],sr))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.title('Music Sample Waveplot')\n",
    "    librosa.display.waveplot(x, sr=sr)\n",
    "    x_stft_spectrum = lb.stft(x, n_fft=1024,hop_length=512,center=True, dtype=np.complex64)\n",
    "    x_stft = librosa.amplitude_to_db(abs(x_stft_spectrum))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.specshow(lb.amplitude_to_db(x_stft, ref=np.max), sr=sr, fmin=lb.note_to_hz('A0'), x_axis='time', y_axis='linear',cmap='coolwarm')\n",
    "    plt.title('Power spectrogram')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    x_cqt = np.abs(librosa.cqt(x, sr=sr, bins_per_octave=bins_per_octave, n_bins=n_bins, fmin=lb.note_to_hz('A0')))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(x_cqt, ref=np.max), sr=sr, x_axis='time', y_axis='cqt_note',cmap='coolwarm')\n",
    "    print(\"CQT Matrix shape\", x_cqt.shape)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Constant-Q power spectrum')\n",
    "    plt.tight_layout()\n",
    "    n_frames=x_cqt.shape[1]\n",
    "    \n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plot_piano_roll(midi_data, 24, 84)\n",
    "    print('There are {} time signature changes'.format(len(midi_data.time_signature_changes)))\n",
    "    print('There are {} instruments'.format(len(midi_data.instruments)))\n",
    "    print('Instrument 1 has {} notes'.format(len(midi_data.instruments[0].notes)))\n",
    "    pianoRoll = midi_data.instruments[0].get_piano_roll(fs=n_frames * 44100. / len(x))\n",
    "    midi_mat = (pianoRoll[MIDInotes[0]:MIDInotes[1] + 1, :n_frames] > 0)\n",
    "    print(\"MIDI Matrix shape\", midi_mat.shape)\n",
    "    plt.figure()\n",
    "    \n",
    "    librosa.display.specshow(midi_mat, sr=sr, bins_per_octave=12, fmin=lb.note_to_hz('A0'), x_axis='time', y_axis='cqt_note')\n",
    "    n_pitch_frame=np.sum(midi_mat, axis=1)\n",
    "    print(n_pitch_frame)\n",
    "    plt.bar(range(MIDInotes[0],MIDInotes[1]+1),n_pitch_frame/np.sum(n_pitch_frame).astype(np.float))\n",
    "    plt.xticks(range(MIDInotes[0],MIDInotes[1]+1,12), lb.midi_to_note(range(MIDInotes[0], MIDInotes[1]+1,12)))\n",
    "    plt.xlabel('Midi note')\n",
    "    plt.ylabel('Note probability')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_audio(audio_file, midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_train=np.transpose(midi_mat)\n",
    "CQT = np.transpose(x_cqt)\n",
    "if midi_train.shape[0]<CQT.shape[0]:\n",
    "    #midi length<CQT length, cut CQT \n",
    "    CQT=CQT[:midi_train.shape[0],:]\n",
    "print(midi_train.shape,CQT.shape)\n",
    "np.save('CQT.npy', CQT)\n",
    "np.save('label.npy', midi_train)\n",
    "\n",
    "data_input.append(np.expand_dims(cut(np.load('CQT.npy'),win_width,kernel_size,overlap=overlap),axis=1))   # 64s,no need to paralellize, I/O is limited ,246s with 5 workers\n",
    "nb_sample.append(data_input[-1].shape[0])\n",
    "print('data loaded')\n",
    "label=[]\n",
    "label.append(np.expand_dims(cut(np.load('label.npy'),win_width,kernel_size,overlap=False).transpose(0,2,1),axis=3))\n",
    "print('label loaded')\n",
    "print(data_input[0].shape)\n",
    "print(nb_sample)\n",
    "print(label[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.transpose(midi_mat)\n",
    "cqt = np.transpose(x_cqt)\n",
    "if label.shape[0]<cqt.shape[0]: \n",
    "    cqt=cqt[:label.shape[0],:]\n",
    "print(label.shape,cqt.shape)\n",
    "file_path='processed_data/files/'+audio_file.split('/')[1].split('.')[0]\n",
    "train_path='processed_data/train/'+audio_file.split('/')[1].split('.')[0]\n",
    "np.save(file_path + '_cqt.npy', cqt)\n",
    "np.save(file_path + '_label.npy', label)\n",
    "nsamples=cqt.shape[0]\n",
    "win_width=32\n",
    "numwin=math.floor(nsamples/win_width)\n",
    "for i in range(numwin):\n",
    "    part_matrix_cqt = cqt[i*win_width:(i+1)*win_width,:]\n",
    "    np.save(train_path+'_'+str(i)+'_cqt',part_matrix_cqt)\n",
    "    part_matrix_label = label[i*win_width:(i+1)*win_width,:]\n",
    "    np.save(train_path+'_'+str(i)+'_label',part_matrix_label)\n",
    "    print(i,part_matrix_cqt.shape,part_matrix_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder='processed_data/train/'\n",
    "train_folder='processed_data/test/'\n",
    "data_folder='processed_data/files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from here\n",
    "class data_loader(Dataset):\n",
    "    def __init__(self, data_dir, win_width, kernel_size, overlap=True, phase='train'):\n",
    "        assert (phase == 'train' or phase == 'val' or phase == 'test')\n",
    "        self.phase = phase\n",
    "        filelist= glob.glob(os.path.join(data_dir,phase)+'/*') #namelist of CQT files and label files\n",
    "        print(phase+'filelist:')\n",
    "        print(filelist)\n",
    "        CQT_name=[f for f in filelist if (f[-7:-4]=='CQT')]\n",
    "        self.input=[]\n",
    "        self.nb_sample=[]\n",
    "\n",
    "        for i in CQT_name:\n",
    "            self.input.append(np.expand_dims(cut(np.load(i),win_width,kernel_size,overlap=overlap),axis=1))   # 64s,no need to paralellize, I/O is limited ,246s with 5 workers\n",
    "            self.nb_sample.append(self.input[-1].shape[0])\n",
    "        print(phase+'data loaded')\n",
    "        label_name=[f[:-7]+'label.npy' for f in CQT_name]\n",
    "        self.label=[]\n",
    "        for i in label_name:\n",
    "            self.label.append(np.expand_dims(cut(np.load(i),win_width,kernel_size,overlap=False).transpose(0,2,1),axis=3))\n",
    "        print(phase+'label loaded')\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #if self.phase!='test':  no real test in our senerios\n",
    "        nb_list, sub_nb = index(idx,self.nb_sample)\n",
    "        return torch.from_numpy(self.input[nb_list][sub_nb].astype(np.float32)),torch.from_numpy(self.label[nb_list][sub_nb].astype(np.float32))   #(1,106,252)/(1,100,88)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.nb_sample)\n",
    "\n",
    "def cut(matrix,win_width,kernel_size,overlap=True,axis=0):  #window cut module\n",
    "# cut the tensor along the first axis by the win_width with a single frame hop\n",
    "    #matrix=np.load(matrix)\n",
    "    l=matrix.shape[0]\n",
    "    cut_matrix=[]\n",
    "    nb_win=math.floor(l/win_width)  #integer division=floor\n",
    "    if not overlap:\n",
    "        for i in range(nb_win):\n",
    "            cut_matrix.append(matrix[i*win_width:(i+1)*win_width,:])\n",
    "    else:\n",
    "        w=matrix.shape[1]\n",
    "        matrix_1=np.concatenate([np.zeros([math.floor(kernel_size/2),w]),matrix,np.zeros([math.floor(kernel_size/2),w])],axis=0)  #padding\n",
    "        cut_matrix = []\n",
    "        for i in range(nb_win):\n",
    "            cut_matrix.append(matrix_1[i * win_width:(i + 1) * win_width+kernel_size-1,:])    #0-104,100-204,...\n",
    "    cut_matrix = np.asarray(cut_matrix)\n",
    "    return cut_matrix\n",
    "\n",
    "def index(idx,nb_sample):\n",
    "    l=len(nb_sample)\n",
    "    accum_nb =0\n",
    "    nb_list=0\n",
    "    sub_nb=0\n",
    "    for i in range(l):\n",
    "        accum_nb+=nb_sample[i]\n",
    "        if idx < accum_nb:\n",
    "            nb_list, sub_nb= i, idx+nb_sample[i]-accum_nb\n",
    "            break\n",
    "    return nb_list,sub_nb\n",
    "\n",
    "\n",
    "def LoadData_main(data_dir, win_width, kernel_size,overlap=True):\n",
    "    trainset=data_loader(data_dir,win_width,kernel_size,overlap=True,phase='train');\n",
    "    valset=data_loader(data_dir,win_width,kernel_size,overlap=True,phase='val');\n",
    "    testset=data_loader(data_dir,win_width,kernel_size,overlap=True,phase='test');\n",
    "    print('all data and label loaded!')\n",
    "    return trainset,valset,testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers=0\n",
    "start_lr=0.01\n",
    "weight_decay=1e-4\n",
    "nb_epochs=1\n",
    "save_freq=1\n",
    "win_width=32  \n",
    "batch_size=32\n",
    "kernel_size=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(1,3), stride=(1,3), return_indices=False)\n",
    "\n",
    "        self.conv1= nn.Sequential(\n",
    "            nn.Conv2d(1, 50, kernel_size=(5,25), stride=1),\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ELU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(50, 50, kernel_size=(3,5), stride=1),\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ELU(inplace=True))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=38400,  out_features=9600),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout3d(p=0.5, inplace=False))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=9600,  out_features=4800),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout3d(p=0.5, inplace=False))\n",
    "        self.fc3 = nn.Linear(in_features=4800,  out_features=32*88)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"1.\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "#         print(\"2.\",x.shape)\n",
    "        x = self.maxpool(x)\n",
    "#         print(\"3.\",x.shape)\n",
    "        x = self.conv2(x)  \n",
    "#         print(\"4.\",x.shape)\n",
    "        x = self.maxpool(x)\n",
    "#         print(\"5.\",x.shape)\n",
    "        x = x.view(-1, 38400)\n",
    "#         print(\"6.\",x.shape)\n",
    "        x = self.fc1(x)\n",
    "#         print(\"7.\",x.shape)\n",
    "        x = self.fc2(x)\n",
    "#         print(\"8.\",x.shape)\n",
    "        x = self.fc3(x)\n",
    "#         print(\"9.\",x.shape)\n",
    "        x = x.view(-1, 88, 32, 1)\n",
    "#         print(\"10.\",x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self, num_hard=0):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "        self.classify_loss = nn.BCEWithLogitsLoss() \n",
    "    def forward(self, output, labels, train=True):\n",
    "        loss = self.classify_loss(\n",
    "           output,labels)\n",
    "        pos = (torch.sigmoid(output) >= 0.5).type(torch.FloatTensor)\n",
    "        pos_recall=labels.sum()\n",
    "        pos_precision=pos.sum()\n",
    "        TP=(pos*labels).sum()\n",
    "        return [loss, TP.item(), pos_precision.item(), pos_recall.item()] #F-score must be computed by whole epoch\n",
    "\n",
    "def get_model():\n",
    "#     print(\"Fetching Model\")\n",
    "    net = Net()\n",
    "    loss = Loss()\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. torch.Size([8, 1, 38, 252])\n",
    "2. torch.Size([8, 50, 34, 228])\n",
    "3. torch.Size([8, 50, 34, 76])\n",
    "4. torch.Size([8, 50, 32, 72])\n",
    "5. torch.Size([8, 50, 32, 24])\n",
    "6. torch.Size([8, 38400])\n",
    "7. torch.Size([8, 19200])\n",
    "8. torch.Size([8, 9600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, loss= get_model()\n",
    "net = DataParallel(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:\\\\Users\\\\Li_Sh\\\\18797proj\\\\someprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data_loader(data_dir,win_width, kernel_size,overlap=True,phase='train')\n",
    "train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = n_workers,\n",
    "        pin_memory=True)   #train/val pin_memory=True, test pin_memory=False\n",
    "\n",
    "dataset=data_loader(data_dir, win_width, kernel_size,overlap=True,phase='val')\n",
    "val_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = n_workers,\n",
    "        pin_memory=True)   #train/val pin_memory=True, test pin_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "        net.parameters(),\n",
    "        start_lr,\n",
    "        weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(epoch,nb_epochs,start_lr):\n",
    "    if epoch <= nb_epochs * 0.5:\n",
    "        lr = start_lr\n",
    "    elif epoch <= nb_epochs * 0.8:\n",
    "        lr = 0.1 * start_lr\n",
    "    else:\n",
    "        lr = 0.01 * start_lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='C:\\\\Users\\\\Li_Sh\\\\18797proj\\\\somemodeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, net, loss, epoch, optimizer, get_lr, save_freq, save_dir,nb_epochs,start_lr):\n",
    "    start_time = time.time()\n",
    "\n",
    "    net.train()\n",
    "    lr = get_lr(epoch,nb_epochs,start_lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "\n",
    "        output = net(data)\n",
    "        print(\"Output\",output.shape,\"Target\",target.shape)\n",
    "        loss_output = loss(output,target)#(8L, 88L, 32L, 1L)/(8L, 1L, 32L, 88L)\n",
    "        \n",
    "#         print (loss_output[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss_output[0].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_output[0] = loss_output[0].item()\n",
    "        metrics.append(loss_output)\n",
    "\n",
    "    if epoch % save_freq == 0:\n",
    "        state_dict = net.module.state_dict()\n",
    "        for key in state_dict.keys():\n",
    "            state_dict[key] = state_dict[key].cpu()\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'save_dir': save_dir,\n",
    "            'state_dict': state_dict\n",
    "            },\n",
    "            os.path.join(save_dir, '%03d.ckpt' % epoch))\n",
    "\n",
    "    end_time = time.time()\n",
    "    metrics = np.asarray(metrics, np.float32)\n",
    "\n",
    "    print('Epoch %03d (lr %.5f),time %3.2f' % (epoch, lr,end_time - start_time))  # Framewise and notewise Accuracy precision,recall,F-score\n",
    "    TP=np.sum(metrics[:, 1])\n",
    "    Precision=TP/np.sum(metrics[:, 2])\n",
    "    Recall=TP/np.sum(metrics[:, 3])\n",
    "    Fscore=2*Precision*Recall/(Precision+Recall)\n",
    "    print('Train:ã€€loss %2.4f, Framewise Precision %3.2f,Recall %3.2f, F-score %3.2f' % (np.mean(metrics[:,0]),Precision,Recall,Fscore))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, net, loss):\n",
    "    start_time = time.time()\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    metrics = []\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target = Variable(target, volatile=True)\n",
    "\n",
    "        output = net(data)\n",
    "        loss_output = loss(output, target, train=False)\n",
    "\n",
    "        loss_output[0] = loss_output[0].item()\n",
    "        metrics.append(loss_output)\n",
    "    end_time = time.time()\n",
    "\n",
    "    metrics = np.asarray(metrics, np.float32)\n",
    "    TP=np.sum(metrics[:, 1])\n",
    "    Precision=TP/np.sum(metrics[:, 2])\n",
    "    Recall=TP/np.sum(metrics[:, 3])\n",
    "    Fscore=2*Precision*Recall/(Precision+Recall)\n",
    "    print('Validation: Loss %2.4f,Framewise Precision %3.2f,Recall %3.2f, F-score %3.2f' % (np.mean(metrics[:,0]),Precision,Recall,Fscore))\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch=0\n",
    "for epoch in range(start_epoch,nb_epochs):\n",
    "    train(train_loader, net, loss, epoch, optimizer, get_lr, save_freq, save_dir,nb_epochs,start_lr)\n",
    "    validate(val_loader, net, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo: load test data\n",
    "dataset=data_loader(data_dir, win_width, kernel_size,overlap=True,phase='test')\n",
    "test_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = n_workers,\n",
    "        pin_memory=True)   #train/val pin_memory=True, test pin_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#demo: 1. use trained network to transcribe the testset music\n",
    "correct = 0\n",
    "total = 0\n",
    "outputlist=torch.tensor([])\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        target = Variable(target, volatile=True)\n",
    "        output = net(data)\n",
    "        output = (output > 0.5).type(torch.FloatTensor)\n",
    "\n",
    "        outputlist=torch.cat((outputlist,output),0)\n",
    "        \n",
    "        \n",
    "        target1 = torch.flatten(target)\n",
    "        output1 = torch.flatten(output)\n",
    "        total += target1.size(0)                    # Increment the total count\n",
    "        correct += (output1 == target1).sum()     # Increment the correct count\n",
    "\n",
    "print(\"Correct Percentage:\",correct.item()/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demo: convert roll matrix to midi music\n",
    "from midiutil.MidiFile import MIDIFile #need to install python lib nidiutil\n",
    "\n",
    "def write_midi_roll_to_midi(x, out_path):\n",
    "    \"\"\"Write out midi_roll to midi file. \n",
    "    \n",
    "    Args: \n",
    "      x: (n_time, n_pitch), midi roll. \n",
    "      out_path: string, path to write out the midi. \n",
    "    \"\"\"\n",
    "    step_sec = float(512)/44100\n",
    "    \n",
    "    def _get_bgn_fin_pairs(ary):\n",
    "        pairs = []\n",
    "        bgn_fr, fin_fr = -1, -1\n",
    "        for i2 in range(1, len(ary)):\n",
    "            if ary[i2-1] == 0 and ary[i2] == 0:\n",
    "                pass\n",
    "            elif ary[i2-1] == 0 and ary[i2] == 1:\n",
    "                bgn_fr = i2\n",
    "            elif ary[i2-1] == 1 and ary[i2] == 0:\n",
    "                fin_fr = i2\n",
    "                if fin_fr > bgn_fr:\n",
    "                    pairs.append((bgn_fr, fin_fr))\n",
    "            elif ary[i2-1] == 1 and ary[i2] == 1:\n",
    "                pass\n",
    "            else:\n",
    "                raise Exception(\"Input must be binary matrix!\")\n",
    "            \n",
    "        return pairs\n",
    "    \n",
    "    # Get (pitch, bgn_frame, fin_frame) triple. \n",
    "    triples = []\n",
    "    (n_time, n_pitch) = x.shape\n",
    "    for i1 in range(n_pitch):\n",
    "        ary = x[:, i1]\n",
    "        pairs_per_pitch = _get_bgn_fin_pairs(ary)\n",
    "        if pairs_per_pitch:\n",
    "            triples_per_pitch = [(i1,) + pair for pair in pairs_per_pitch]\n",
    "            triples += triples_per_pitch\n",
    "    \n",
    "    # Sort by begin frame. \n",
    "    triples = sorted(triples, key=lambda x: x[1])\n",
    "    \n",
    "    # Write out midi. \n",
    "    MyMIDI = MIDIFile(1)    # Create the MIDIFile Object with 1 track\n",
    "    track = 0   \n",
    "    time = 0\n",
    "    tempo = 120\n",
    "    beat_per_sec = 60. / float(tempo)\n",
    "    MyMIDI.addTrackName(track, time, \"Sample Track\")  # Add track name \n",
    "    MyMIDI.addTempo(track, time, tempo)   # Add track tempo\n",
    "    \n",
    "    for triple in triples:\n",
    "        (midi_pitch, bgn_fr, fin_fr) = triple\n",
    "        print(\"pitch, bgn, end for each note\",triple)\n",
    "        bgn_beat = bgn_fr * step_sec / float(beat_per_sec)\n",
    "        fin_beat = fin_fr * step_sec / float(beat_per_sec)\n",
    "        dur_beat = fin_beat - bgn_beat\n",
    "        print(\"note begin:\",bgn_beat)\n",
    "        print(\"duration (beat) of this note:\",dur_beat)\n",
    "        MyMIDI.addNote(track=0,     # The track to which the note is added.\n",
    "                    channel=0,   # the MIDI channel to assign to the note. [Integer, 0-15]\n",
    "                    pitch=midi_pitch,    # the MIDI pitch number [Integer, 0-127].\n",
    "                    time=bgn_beat,      # the time (in beats) at which the note sounds [Float].\n",
    "                    duration=dur_beat,  # the duration of the note (in beats) [Float].\n",
    "                    volume=100)  # the volume (velocity) of the note. [Integer, 0-127].\n",
    "    out_file = open(out_path, 'wb')\n",
    "    MyMIDI.writeFile(out_file)\n",
    "    out_file.close()\n",
    "    print(\"successfully wrote the midi file!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for demo: convert nn output to roll matrix and wirte midi accordingly, show the resulting roll mat\n",
    "import os.path as osp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(outputlist.shape)\n",
    "Alloutput=outputlist.permute(1,2,3,0)\n",
    "print(Alloutput.shape)\n",
    "\n",
    "Alloutput=Alloutput.contiguous()\n",
    "Alloutput=Alloutput.view(88,-1)#get the midiroll matrix\n",
    "Alloutput=Alloutput.permute(1,0) #transpose the midiroll mat to fit in the write midi function\n",
    "Alloutput=Alloutput.numpy()\n",
    "print(Alloutput.shape) \n",
    "\n",
    "pitch_bgn=21\n",
    "roll_mat = np.zeros((Alloutput.shape[0]+1, 128))\n",
    "roll_mat[1:, pitch_bgn : pitch_bgn + 88] = Alloutput\n",
    "print(\"roll_mat shape:\",roll_mat.shape)\n",
    "\n",
    "roll_mat_b=(roll_mat==1)\n",
    "print(roll_mat_b.shape)\n",
    "\n",
    "outaudio_path='C:\\\\Users\\\\Li_Sh\\\\18797proj\\\\outaudio.mid'\n",
    "write_midi_roll_to_midi(roll_mat_b, outaudio_path) #write roll mat to midi\n",
    "\n",
    "#plot the roll matrix\n",
    "fig = plt.figure()\n",
    "plt.matshow(roll_mat.T,origin='lower', aspect='auto')\n",
    "plt.xlabel('time frame')\n",
    "plt.ylabel('note frame')\n",
    "plt.title('roll matrix after transcription', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "#reread the midi file and plot its roll \n",
    "x_midi = pretty_midi.PrettyMIDI(outaudio_path)\n",
    "plt.figure(figsize=[12,4])\n",
    "start_pitch=0\n",
    "end_pitch=127\n",
    "librosa.display.specshow(x_midi.get_piano_roll(100)[start_pitch:end_pitch],\n",
    "                             hop_length=1, sr=100, x_axis='time', y_axis='cqt_note',\n",
    "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
    "plt.title('roll matrix after transcription', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
